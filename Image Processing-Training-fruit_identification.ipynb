{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from sklearn.datasets import load_files\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import np_utils\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/imranzaman5202/99-acc-fruits-recognition-using-nn/notebook\n",
    "We are loading all training and testing data\n",
    "Saving inputs/images in x_train of training data and saving labels in y_train\n",
    "Saving inputs/images in x_test of testing data and saving labels in y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Apple Braeburn', 'Apple Golden 1', 'Apple Golden 2', 'Apple Golden 3', 'Apple Granny Smith', 'Apple Red 1', 'Apple Red 2', 'Apple Red 3', 'Apple Red Delicious', 'Apple Red Yellow', 'Apricot', 'Avocado', 'Avocado ripe', 'Banana', 'Banana Red', 'Cactus fruit', 'Cantaloupe 1', 'Cantaloupe 2', 'Carambula', 'Cherry 1', 'Cherry 2', 'Cherry Rainier', 'Cherry Wax Black', 'Cherry Wax Red', 'Cherry Wax Yellow', 'Clementine', 'Cocos', 'Dates', 'Granadilla', 'Grape Pink', 'Grape White', 'Grape White 2', 'Grapefruit Pink', 'Grapefruit White', 'Guava', 'Huckleberry', 'Kaki', 'Kiwi', 'Kumquats', 'Lemon', 'Lemon Meyer', 'Limes', 'Lychee', 'Mandarine', 'Mango', 'Maracuja', 'Melon Piel de Sapo', 'Mulberry', 'Nectarine', 'Orange', 'Papaya', 'Passion Fruit', 'Peach', 'Peach Flat', 'Pear', 'Pear Abate', 'Pear Monster', 'Pear Williams', 'Pepino', 'Physalis', 'Physalis with Husk', 'Pineapple', 'Pineapple Mini', 'Pitahaya Red', 'Plum', 'Pomegranate', 'Quince', 'Rambutan', 'Raspberry', 'Salak', 'Strawberry', 'Strawberry Wedge', 'Tamarillo', 'Tangelo', 'Tomato 1', 'Tomato 2', 'Tomato 3', 'Tomato 4', 'Tomato Cherry Red', 'Tomato Maroon', 'Walnut']\n",
      "['Apple Braeburn', 'Apple Golden 1', 'Apple Golden 2', 'Apple Golden 3', 'Apple Granny Smith', 'Apple Red 1', 'Apple Red 2', 'Apple Red 3', 'Apple Red Delicious', 'Apple Red Yellow', 'Apricot', 'Avocado', 'Avocado ripe', 'Banana', 'Banana Red', 'Cactus fruit', 'Cantaloupe 1', 'Cantaloupe 2', 'Carambula', 'Cherry 1', 'Cherry 2', 'Cherry Rainier', 'Cherry Wax Black', 'Cherry Wax Red', 'Cherry Wax Yellow', 'Clementine', 'Cocos', 'Dates', 'Granadilla', 'Grape Pink', 'Grape White', 'Grape White 2', 'Grapefruit Pink', 'Grapefruit White', 'Guava', 'Huckleberry', 'Kaki', 'Kiwi', 'Kumquats', 'Lemon', 'Lemon Meyer', 'Limes', 'Lychee', 'Mandarine', 'Mango', 'Maracuja', 'Melon Piel de Sapo', 'Mulberry', 'Nectarine', 'Orange', 'Papaya', 'Passion Fruit', 'Peach', 'Peach Flat', 'Pear', 'Pear Abate', 'Pear Monster', 'Pear Williams', 'Pepino', 'Physalis', 'Physalis with Husk', 'Pineapple', 'Pineapple Mini', 'Pitahaya Red', 'Plum', 'Pomegranate', 'Quince', 'Rambutan', 'Raspberry', 'Salak', 'Strawberry', 'Strawberry Wedge', 'Tamarillo', 'Tangelo', 'Tomato 1', 'Tomato 2', 'Tomato 3', 'Tomato 4', 'Tomato Cherry Red', 'Tomato Maroon', 'Walnut']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = './Data/fruits-360_dataset/fruits-360/Training/'\n",
    "test_dir = './Data/fruits-360_dataset/fruits-360/Test/'\n",
    "\n",
    "def load_dataset(data_path):\n",
    "    data_loading = load_files(data_path)\n",
    "    print(data_loading['target_names'])\n",
    "    files_add = np.array(data_loading['filenames'])\n",
    "    targets_fruits = np.array(data_loading['target'])\n",
    "    target_labels_fruits = np.array(data_loading['target_names'])\n",
    "    return files_add,targets_fruits,target_labels_fruits\n",
    "    \n",
    "x_train, y_train,target_labels = load_dataset(train_dir)\n",
    "x_test, y_test,_ = load_dataset(test_dir)\n",
    "\n",
    "no_of_classes = len(np.unique(y_train))\n",
    "no_of_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np_utils.to_categorical(y_train,no_of_classes)\n",
    "y_test = np_utils.to_categorical(y_test,no_of_classes)\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vaildation X :  (7000,)\n",
      "Vaildation y : (7000, 81)\n",
      "Test X :  (6877,)\n",
      "Test y :  (6877, 81)\n"
     ]
    }
   ],
   "source": [
    "x_test,x_valid = x_test[7000:],x_test[:7000]\n",
    "y_test,y_vaild = y_test[7000:],y_test[:7000]\n",
    "print('Vaildation X : ',x_valid.shape)\n",
    "print('Vaildation y :',y_vaild.shape)\n",
    "print('Test X : ',x_test.shape)\n",
    "print('Test y : ',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape :  (41322, 100, 100, 3)\n",
      "Validation set shape :  (7000, 100, 100, 3)\n",
      "Test set shape :  (6877, 100, 100, 3)\n",
      "1st training image shape  (100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "def convert_image_to_array_form(files):\n",
    "    images_array=[]\n",
    "    for file in files:\n",
    "        images_array.append(img_to_array(load_img(file)))\n",
    "    return images_array\n",
    "\n",
    "x_train = np.array(convert_image_to_array_form(x_train))\n",
    "print('Training set shape : ',x_train.shape)\n",
    "\n",
    "x_valid = np.array(convert_image_to_array_form(x_valid))\n",
    "print('Validation set shape : ',x_valid.shape)\n",
    "\n",
    "x_test = np.array(convert_image_to_array_form(x_test))\n",
    "print('Test set shape : ',x_test.shape)\n",
    "\n",
    "print('1st training image shape ',x_train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')/255\n",
    "x_valid = x_valid.astype('float32')/255\n",
    "x_test = x_test.astype('float32')/255\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1\n",
    "We are calling base Sequancial model for training and for further tuning of parameters on image data. We must call it when we work on the keras, tensorflow based libraries.\n",
    "Step 2\n",
    "Conv2D is 2D convolutional layer(where filters are applied to original image with specific features map to reduce the number of features), Conv2D layer create the convolution kernel(fixed size of boxes to apply on the image like below in the example gif) that take input of 16 filters which help to produce a tensor of outputs. We are giving input of the image with size of 100 width and 100 height and 3 is the channel for RGB.\n",
    "\n",
    "Activation function is node that is put at the end of all layers of neural network model or in between neural network layers. Activation function help to decide which neuron should be pass and which neuron should fire. So activation function of node defines the output of that node given an input or set of inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensorflow_based_model():\n",
    "    model = Sequential() #step 1\n",
    "    model.add(Conv2D(filters = 16, kernel_size = 2,input_shape=(100,100,3),padding='same')) #step2\n",
    "    model.add(Activation('relu'))  # step3\n",
    "    model.add(MaxPooling2D(pool_size=2)) #step4\n",
    "    model.add(Conv2D(filters = 32,kernel_size = 2,activation= 'relu',padding='same')) #repeating step 2 and step3 but with more filters of 32\n",
    "    model.add(MaxPooling2D(pool_size=2)) #repeating step 4 again\n",
    "    model.add(Conv2D(filters = 64,kernel_size = 2,activation= 'relu',padding='same')) #repeating step 2 and step3 but with more filters of 64\n",
    "    model.add(MaxPooling2D(pool_size=2)) #repeating step 4 again\n",
    "    model.add(Conv2D(filters = 128,kernel_size = 2,activation= 'relu',padding='same')) #repeating step 2 and step3 but with more filters of 64\n",
    "    model.add(MaxPooling2D(pool_size=2)) #repeating step 4 again\n",
    "    model.add(Dropout(0.3)) # step5\n",
    "    model.add(Flatten()) #step 6\n",
    "    model.add(Dense(150)) #step 7\n",
    "    model.add(Activation('relu')) # setp 3\n",
    "    model.add(Dropout(0.4)) # step 5\n",
    "    model.add(Dense(81,activation = 'softmax')) # setp3 and step7. but this time, we are using activation function as softmax (if we train on two classes then we set sigmoid)\n",
    "    return model #function returning the value when we call it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1292/1292 - 128s - loss: 1.1168 - accuracy: 0.6893 - val_loss: 0.1893 - val_accuracy: 0.9509\n",
      "Epoch 2/30\n"
     ]
    }
   ],
   "source": [
    "model = tensorflow_based_model() # here we are calling the function of created model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy']) \n",
    "\n",
    "history = model.fit(x_train,y_train,\n",
    "        batch_size = 32,\n",
    "        epochs=30,\n",
    "        validation_data=(x_valid, y_vaild),\n",
    "        verbose=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)\n",
    "fig = plt.figure(figsize=(16, 9))\n",
    "for i, idx in enumerate(np.random.choice(x_test.shape[0], size=16, replace=False)):\n",
    "    ax = fig.add_subplot(4, 4, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(x_test[idx]))\n",
    "    pred_idx = np.argmax(predictions[idx])\n",
    "    true_idx = np.argmax(y_test[idx])\n",
    "    ax.set_title(\"{} ({})\".format(target_labels[pred_idx], target_labels[true_idx]),\n",
    "                 color=(\"green\" if pred_idx == true_idx else \"red\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
